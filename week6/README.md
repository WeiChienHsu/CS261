# Hash Map (Dictionary)

a very specific type of search. Elements are placed into the dictionary in key/value pairs.

To do a retrieval, the user supplies a key, and the container returns the associated value. Each key identifies one entry; that is, each key is unique.

- get(key)
- put(key, value)
- containsKey(key)
- removeKey(key)
- keys()
- size

## Example Application: Concordance
Count the number of times each word appears in a selection of texts.
- Keys: Unique words from the text
- Values: count of each word

```c
struct association {
  KEYTYPE key;
  VALUETYPE value;
};

void dyArrayDictionaryGet (struct dynArray*da, KEYTYPE key, VALUETYPE *valptr) {
  for(int i = 0; i < da -> size; i++) {
    if(strcmp(da -> data[i] -> key, key) == 0) {
      *valptr = da -> data[i] -> value;
    }
  }
}

void dyArrayDictionaryPut (struct dynArray * da, KEYTYPE key, VALUETYPE val) {
  struct association *ap;
  if(dyArrayDictionaryContainsKey(da, key)) {
    dyArrayDictionaryRemoveKey(da, key);
  }

  ap = (struct association*) malloc (sizeof(struct association));
  assert(ap != 0);
  ap -> key = key;
  ap -> value = value;
  dyArrayAdd(da, ap); /* Store assocation into Dynamic Array */
  
  }

int dyArrayDictionaryContainsKey (struct dynArray * da, KEYTYPEkey) {
  for(int i = 0; i < da -> size; i++) {
    if(strcmp(key, da -> data[i] -> key) == 0) {
      return 1;
    }
  }
  return 0;
}

void dyArrayDictionaryRemoveKey (struct dynArray * da, KEYTYPEkey) {
  for(int i = 0; i < da -> size; i++) {
    if(strcmp(key, da -> data[i] -> key) == 0) {
      strcut association *temp;
      temp = da -> data[i];
      removeAtDynArr(da, i);
      free(temp);
      break;
    }
  }
}
```

***

# Hashing Function

Almost any process that converts a value into an integer can be used as a hash function. 

So in O(1) time Amy can change a name into an integer index value, then use this value to index into a table. This is faster than an ordered data structure. 

What Amy has discovered is called a "perfect hash function".
(No collisions in whole cases which means the character chose to be the key is unique) 
Hash functions are only required to return a value that is integer, not necessarily positive. So it is common to surround the calculation with abs( ) to ensure a positive value.


- FAST (Constant time)
- Produce UNIOFRMLY distributed indices
- REPEATABLE



## Computing a Hash Table index 

### 1. Transform the value (or key) to an integer (using the hash function)

#### Mapping:
Map a part of the key into an integer.
- A letter to its position in the alphabet

#### Folding:
Key partitioned into parts which are then combined using efficient operations.
- Summing the values of each character in a string

#### Shifting:
Get rid of high or low order bits that are not random
- If keys are always even, shift off the low order bit

#### Casts:
Converting a numeric type into an integer
- Casting a character to an int to get its ASCII value.
- Data -> a value associated with current time
- Double -> a value generated by its bitwise representation
- Integer -> the int value itself
- String -> a folded sum of the character values
- URL -> the hash on the host name

### 2. Map that integer to a valid hash table index 

#### Use modulus operator % with table size
- idx = hash(val) % size

#### Use only postive arithmetic or take absolute value

#### To get a good distribution of indices, prime numbers make the best table size

***

# Collisions

Collisions occur when two values hash to the same index.

## Open Address Hashing(Probing) - Deal with collisions

If a spot is full, probe prob for next empty spot.

### Adding - Linear probing

1. All values are stored in an array.
2. Hash value is used to find initial index to try.
3. If that position is filled, the next position is examined, then the next and so on until an empty position is found.(Linear Probing)
4. Positions that are not yet filled are given a null value.

| 0 - aiqy | 1 - bjrz | 2 - cks | 3 - dlt | 4 - emu | 5 - fnv | 6 - gow | 7 - hpx |
|:--------:|:--------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|
| amIna    |          |         | anDy    | alEssia | alFred  |         | asPen   |


If AnNe now joins the club, we will find that the hash value (namely, 5) is the same as for AlFred. 

So to find a location to store the value Anne we "probe" for the next free location.

- This means to simply move forward, position by position, "until an empty location is found".

| 0 - aiqy | 1 - bjrz | 2 - cks | 3 - dlt | 4 - emu | 5 - fnv | 6 - gow | 7 - hpx |
|:--------:|:--------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|
| amIna    |   AgNes  |         | anDy    | alEssia | alFred  |   AnNe  | asPen   |


AgNes wishes to join the club. Her hash value, 6, is already filled. The probe
moves forward to the next position, and when the end of the array is reached it continues with the first element.

Finally, suppose Alan(0) wishes to join the club.

| 0 - aiqy | 1 - bjrz | 2 - cks | 3 - dlt | 4 - emu | 5 - fnv | 6 - gow | 7 - hpx |
|:--------:|:--------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|
| amIna    |   AgNes  |AlAn     | anDy    | alEssia | alFred  |   AnNe  | asPen   |

### Contains 
1. Compute the hash function to to find initial index (If found, return true)
2. probe forward until - value is found (return true) or meet empty location (return false)

- Search time is not uniform.


### Remove

| 0 - aiqy | 1 - bjrz | 2 - cks | 3 - dlt | 4 - emu | 5 - fnv | 6 - gow | 7 - hpx |
|:--------:|:--------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|
| amIna    |   AgNes  |AlAn     | anDy    | alEssia | alFred  |   AnNe  | asPen   |

If we removed agnes -> alan would be found in probing

| 0 - aiqy | 1 - bjrz | 2 - cks | 3 - dlt | 4 - emu | 5 - fnv | 6 - gow | 7 - hpx |
|:--------:|:--------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|
| amIna    |          |AlAn     | anDy    | alEssia | alFred  |   AnNe  | asPen   |

Instead deleteing the value and leave it empty to cause problem when we need to prob next time:

1. Simple solution: Dont allow removal. (Words dont get removed from a spell checker)
2. Replace removed item with "Tombstone".

### Tombstone
- Special value that marks deleted entry
- Can be replaced when adding new entry 
- But doesn't halt search during contains or remove

| 0 - aiqy | 1 - bjrz | 2 - cks | 3 - dlt | 4 - emu | 5 - fnv | 6 - gow | 7 - hpx |
|:--------:|:--------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|
| amIna    |   _TS_   |AlAn     | anDy    | alEssia | alFred  |   AnNe  | asPen   |



## Load Factor

l = n (# of elements) / m (size of table)

The ratio of the number of elements to the table size. For open address hashing the load factor is never larger than 1. 

### Clustering

| 0 - aiqy | 1 - bjrz | 2 - cks | 3 - dlt | 4 - emu | 5 - fnv | 6 - gow | 7 - hpx |
|:--------:|:--------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|
| amIna    |          |         |  AlAn   | alEssia | alFred  |         | asPen   |

Assuming uniform distribution of hash values what's the probability that the next value will end up in index 1, 2, 6 :  3/8, 1/8, 4/8

As load factor gets larger, the tendency to cluster increases, resulting in longer search times upon collision.

### Solving Clustering

a common solution to a full hash table is to "move all values into a new and larger table" when the load factor becomes larger than some threshold, such as 0.75. 

To do so a new table is created, and every entry in the old table is "rehashed", this time "dividing by the new table size to find the index to place into the new table".

## Algorithm Complexity 

### Assumptions
Time to compute hash funciton is constant
Worst case analysis : All values hash to same position
Best case analysis : hash function uniformly distributes the values

### Find element opeartion
Worst case for open addressing : O(n)
Best Case for open addressing : O(1)

### Average Case
1 / (1 - Load Factor) -> When load factor increase, search time increase dramactialy

So, its very important to keep Load Factor low.

***

## Open Address Hashing Implementaion using Dynamic Array

- Why Stored pointers in the array : Need to tell if a position is empty or not : Store only poiters & check for null (== 0)

```c

struct openHashTable {
  TYPE ** table; /* pointer points to the pointer stored in array */
  int tableSize;
  int count;
};

/* Iniitial Size of the table is 17 and 
   Resized if the load factor larger than 0.75 */
void initOpenHashTable (struct openHashTable *ht, int size) {
  assert(size > 0);
  ht -> table = (TYPE **) malloc (size * sizeof(TYPE *));
  assert(ht -> table != 0);
  /* Fill in the array */
  for(int i = 0; i < size; i++) {
    ht -> table[i] = 0; /* Initialize empty */
  }
  ht -> tableSize = size;
  ht -> count = 0;
}

int openHashTableSize(struct openHashTable *ht) {
  return ht -> count;
}

void openHashTableAdd(struct openHashTable *ht, TYPE *newValue) {
  /* Make sure we have space and under the load factor 0.75 */
  /* Load Factor = number of elements / size of table */
  if((ht -> count / (double) ht -> tableSize) > 0.75) {
    _resizeOpenHashTable(ht);
  }
  ht -> count ++;

  index = HASH(newValue) % ht -> tableSize; /* Hash and get a right position */


  /* Deal with the negative integer base on different hashing function */
  if(index < 0) index += ht -> tableSize; 

  /* Add the new value into that index */
  while(index >= 0) {
    /* After probing, the index exceed size of table */
    if(index == ht -> tableSize) {
      index = 0;
    }

    if(ht -> table[index] == 0) {
      /* Add the new value into this empty position and end the loop */
      ht -> table[index] = newValue;
      index = -1;
    }
    else {
      /* That position was not empty, probing */
      index ++;
    }
  }
}

int openHashTableContains(struct openHashTable *ht, TYPE newValue) {
  int index = HASH(newValue) % ht -> tableSize;
  if(index < 0) index += ht -> tableSize;

  while(ht -> table[index] != 0) {
    if(compare(ht -> table[index], newValue) == 0) {
      /* Fount the target */
      reutrn 1
    }

    /* Probing to find next position */
    index ++;

    /* Modify the value of index */
    if(index == ht -> tableSize) {
      index = 0;
    }
  }

  return 0;
}

void _resizeOpenHashTable(struct openHashTable *ht) {
  int originalSize = ht -> tableSize;
  TYPE **temp = ht -> table;
  initOpenHashTable(ht, originalSize * 2);

  for(int i = 0; i < originalSize; i++) {
    if(temp[i] != 0) {
      openHashTableAdd(ht, temp[i]);
    }
  }
  free(temp);
}

```

***

## Chaining (or Buckets)

Keep a collection at each table entry by Linked List.

Each element in the array (the hash table) is a header for a linked list. All elements that hash into the same location will be stored in the list.

### Load Facotr

l = n (# of elements) / m (size of table)

Load Factor represents average number of elements in each bucket
- For chaining, load factor can be greater than 1.


### Implementation of Chaining by Linked List

```c
struct hlink {
  TYPE value;
  struct hlink *next;
};

struct HashTable {
  struct hlink **table; /* Hash Table -> Array of Lists */
  int tableSize;
  int count;
}

void initHashTable(struct HashTable *ht, int size) {
  ht -> tableSize = size;
  ht -> count = 0;
  ht -> table = malloc(size * sizeof(struct hlink *));
  assert(ht -> table != 0);
  /* Initilize each address of its linked list */
  for(int i = 0; i < size; i++) {
    ht -> table[i] = 0;
  }
}

void HashTableAdd(struct HashTable *ht, TYPE newValue) {

}


TYPE HashTableContains(struct HashTable *ht, TYPE target) {

}


void HashTableRemove(struct HashTable *ht, TYPE value) {

}

void HashTableResize(struct HashTabke *ht) {

}




```


***

## Caching

Indexing into a hash table is extremely fast, even faster than searching a skip list or an AVL tree. When a search request is received, the cache will examine the hash table. If the value is found in the cache, it is simply returned. If it is not found, then the original data structure is examined.


## Hash Table with Buckets - collisions

A hash table that uses buckets is really a combination of an array and a linked list. Each element in the array (the hash table) is a header for a linked list. All elements that hash into the same location will be stored in the list. For the Bag type abstraction the link stores only a value and a pointer to the next link. For a dictionary type abstraction, such as we will construct, the link stores the key, the value associated with the key, and the pointer to the next link.


Each operation on the hash table divides into two steps. First, the element is hashed and the remainder taken after dividing by the table size. This yields a table index. Next, linked list indicated by the table index is examined. The algorithms for the latter are very similar to those used in the linked list.

### Compare Probing and Chaining

As with open address hash tables, the load factor (λ) is defined as the number of elements divided by the table size. In this structure the load factor can be larger than one, and represents the average number of elements stored in each list, assuming that the hash function distributes elements uniformly over all positions. 

Since the running time of the contains test and removal is proportional to the length of the list, they are O(λ). Therefore the execution time for hash tables is fast only if the load factor remains small. A typical technique is to resize the table (doubling the size, as with the vector and the open address hash table) if the load factor becomes larger than 10.